+++
Categories = ["polly"]
Description = ""
Tags = ["polly"]
date = "2017-04-03"
title = "Work report: April 6"
+++


## Work today
- got Polly built on Pascal
- started writing CUDA code
- implemented 2D Cyclic cellular automata with CUDA


### Video

#### NOTE: load video *fully* and then watch, otherwise video appears choppy!

[![asciicast](https://asciinema.org/a/111474.png)](https://asciinema.org/a/111474?t=13)
- [Asciinema video link: click here](https://asciinema.org/a/111474)


##### Cyclic cellular automata computed on the GPU
```cpp
#include <stdio.h>
#include <cuda_runtime.h>
#include <assert.h>
#include <stdlib.h>
#include <time.h>
#include <ncurses/curses.h>
#include <unistd.h>

#define NUM_COLORS 10
#define DELAY 30000

#define ROWS 80
#define COLS 80

//Macro for checking cuda errors following a cuda launch or api call
#define cudaCheckError() {                                          \
    cudaError_t e=cudaGetLastError();                                 \
    if(e!=cudaSuccess) {                                              \
        printf("Cuda failure %s:%d: '%s'\n",__FILE__,__LINE__,cudaGetErrorString(e));           \
        exit(0); \
    }                                                                 \
}

#define get(arr, x, y) arr[((x) % ROWS) * COLS + ((y) % COLS)]
#define set(arr, x, y, val) arr[((x) % ROWS) * COLS + ((y) % COLS)] = val;

__device__ __managed__ int pingpong[2][ROWS * COLS];
__device__ __managed__ int i;

__global__ void NaiveStep()
{
    int *oldGrid = pingpong[i];
    int *newGrid = pingpong[(i + 1) % 2];
    const int x = blockIdx.x*blockDim.x+threadIdx.x;
    const int y = blockIdx.y*blockDim.y+threadIdx.y;


    if (x < ROWS && y < COLS) {
        const int old = get(oldGrid, x, y);
        const int wantedNext = (old + 1) % NUM_COLORS;
        int dx[] = {1, 0, -1, 0};
        int dy[] = {0, 1, 0, -1};

        set(newGrid, x, y, old);
        for(int i = 0; i < 4; i++) {
            if (get(oldGrid,x + dx[i], y + dy[i])  == wantedNext) {
                set(newGrid, x, y, wantedNext);
                break;
            }
        }


    }
}

void print_automata(int *grid) {
    static const char outs[] = " .:-=+*#%@";
    assert(sizeof(outs) / sizeof(char) >= NUM_COLORS && "do not have enough "
            "characters to print!");

    for(int i = 0; i < ROWS; i++) {
        for(int j = 0; j < COLS; j++) {
            const char ch = outs[grid[i * COLS + j]];
            mvaddch(i, j, ch);
        }
    }
}

void init_automata(int *automata) {
    for (int r = 0; r < ROWS; r++) {
        for(int c = 0; c < COLS; c++) {
            automata[r * COLS + c] = rand() % NUM_COLORS;
        }
    }
}

int main(void)
{
    i = 0;

    srand(time(NULL));
    init_automata(pingpong[0]);

    static const int THREADS_ALONG_AXIS = 10;
    dim3 dimBlock(ROWS / THREADS_ALONG_AXIS, COLS / THREADS_ALONG_AXIS);
    dim3 dimGrid(THREADS_ALONG_AXIS, THREADS_ALONG_AXIS);


    initscr();
    noecho();
    curs_set(FALSE);

   do {
        for(int _ = 0; _ < 100; _++) {
            const int newi = (i + 1) % 2;
            NaiveStep<<<dimGrid, dimBlock>>>();
            cudaCheckError();
            cudaDeviceSynchronize();


            if (true){
                const int randr = rand() % ROWS;
                const int randc = rand() % COLS;
                const int WINDOW_HALFDIM = 4;

                for(int dr = -WINDOW_HALFDIM; dr <= WINDOW_HALFDIM; dr++) {
                    for(int dc = -WINDOW_HALFDIM; dc <= WINDOW_HALFDIM; dc++) {
                        set(pingpong[newi], randr + dr, randc + dc,
                                rand() % NUM_COLORS);
                    }
                }

            }

            clear();
            print_automata(pingpong[i]);
            refresh();
            usleep(DELAY);

            i = newi;
        }
    } while(getchar() != 'q');

    endwin();
    for(int i = 0; i < 2; i++) {
        cudaFree(pingpong[i]);
    }
    cudaDeviceReset();
}
```

###### Makefile:
```
all: build run

build:
	nvcc -o test.out test.cu -lncurses -arch=sm_35

run:
	@echo "----"
	@./test.out
```

- Use the "fused memory" or whatever marketing calls it, not `__managed__`
- Read through `polly-acc`, understand low-level CUDA API